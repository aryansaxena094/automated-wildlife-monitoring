{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8168958,"sourceType":"datasetVersion","datasetId":4834235}],"dockerImageVersionId":30703,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from torch.utils.data import DataLoader, random_split\nfrom torchvision import datasets, transforms, models\nimport torch\nimport numpy as np\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import classification_report\nfrom torch.utils.tensorboard import SummaryWriter\nfrom sklearn.manifold import TSNE\nfrom torch.optim.lr_scheduler import StepLR\nimport time\nimport torch.nn as nn\nfrom datetime import datetime","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-19T21:26:48.954910Z","iopub.execute_input":"2024-04-19T21:26:48.955270Z","iopub.status.idle":"2024-04-19T21:26:48.961418Z","shell.execute_reply.started":"2024-04-19T21:26:48.955242Z","shell.execute_reply":"2024-04-19T21:26:48.960379Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.Resize(256),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(15),\n    transforms.CenterCrop(224),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n    transforms.ColorJitter()\n])\n\nfull_dataset = datasets.ImageFolder('/kaggle/input/animal30/mammals', transform=transform)\nclass_counts = {class_name: 0 for class_name in full_dataset.classes}\nfor _, index in full_dataset.samples:\n    class_name = full_dataset.classes[index]\n    class_counts[class_name] += 1\nprint(\"Total number of classes:\", len(full_dataset.classes))\nprint(\"Class names:\", full_dataset.classes)\nprint(\"Number of images per class:\")\nfor class_name, count in class_counts.items():\n    print(f\" - {class_name}: {count}\")","metadata":{"execution":{"iopub.status.busy":"2024-04-19T21:26:51.497210Z","iopub.execute_input":"2024-04-19T21:26:51.497931Z","iopub.status.idle":"2024-04-19T21:26:52.788215Z","shell.execute_reply.started":"2024-04-19T21:26:51.497900Z","shell.execute_reply":"2024-04-19T21:26:52.787282Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Total number of classes: 30\nClass names: ['african_elephant', 'alpaca', 'american_bison', 'anteater', 'arctic_fox', 'armadillo', 'baboon', 'badger', 'brown_bear', 'camel', 'giraffe', 'groundhog', 'highland_cattle', 'horse', 'jackal', 'kangaroo', 'koala', 'mongoose', 'mountain_goat', 'opossum', 'orangutan', 'polar_bear', 'porcupine', 'red_panda', 'rhinoceros', 'weasel', 'wildebeest', 'wombat', 'yak', 'zebra']\nNumber of images per class:\n - african_elephant: 347\n - alpaca: 333\n - american_bison: 343\n - anteater: 299\n - arctic_fox: 315\n - armadillo: 331\n - baboon: 330\n - badger: 310\n - brown_bear: 300\n - camel: 254\n - giraffe: 305\n - groundhog: 309\n - highland_cattle: 311\n - horse: 303\n - jackal: 278\n - kangaroo: 317\n - koala: 319\n - mongoose: 287\n - mountain_goat: 328\n - opossum: 330\n - orangutan: 340\n - polar_bear: 356\n - porcupine: 321\n - red_panda: 329\n - rhinoceros: 274\n - weasel: 282\n - wildebeest: 307\n - wombat: 315\n - yak: 254\n - zebra: 272\n","output_type":"stream"}]},{"cell_type":"code","source":"train_size = int(0.8 * len(full_dataset))\ntest_validation_size = len(full_dataset) - train_size\nvalidation_size = test_validation_size // 2\ntest_size = test_validation_size - validation_size\n\ntrain_dataset, test_validation_dataset = random_split(full_dataset, [train_size, test_validation_size])\nvalidation_dataset, test_dataset = random_split(test_validation_dataset, [validation_size, test_size])\n\nprint(\"Size of the entire Dataset: \", len(full_dataset))\nprint(\"Size of the training Dataset: \", len(train_dataset))\nprint(\"Size of the validation Dataset: \", len(validation_dataset))\nprint(\"Size of the test Dataset: \", len(test_dataset))\n\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\nvalidation_loader = DataLoader(validation_dataset, batch_size=32, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-19T21:27:44.474980Z","iopub.execute_input":"2024-04-19T21:27:44.475820Z","iopub.status.idle":"2024-04-19T21:27:44.491131Z","shell.execute_reply.started":"2024-04-19T21:27:44.475785Z","shell.execute_reply":"2024-04-19T21:27:44.490132Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Size of the entire Dataset:  9299\nSize of the training Dataset:  7439\nSize of the validation Dataset:  930\nSize of the test Dataset:  930\n","output_type":"stream"}]},{"cell_type":"code","source":"resnet18 = models.resnet18(pretrained=False)\nnum_classes = 30\nresnet18.fc = nn.Linear(resnet18.fc.in_features, num_classes)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nresnet18.to(device)\ncriterion = nn.CrossEntropyLoss()\nlearning_rate = 0.009\noptimizer = torch.optim.SGD(resnet18.parameters(), lr=learning_rate, momentum=0.9)\nscheduler = StepLR(optimizer, step_size=5, gamma=0.1)\n\nsimple_name = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\nwriter = SummaryWriter(f'runs/{simple_name}')\nmodel_save_path = 'resnet18_best_model.pth'","metadata":{"execution":{"iopub.status.busy":"2024-04-19T21:56:16.932413Z","iopub.execute_input":"2024-04-19T21:56:16.932813Z","iopub.status.idle":"2024-04-19T21:56:17.148837Z","shell.execute_reply.started":"2024-04-19T21:56:16.932779Z","shell.execute_reply":"2024-04-19T21:56:17.148081Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"patience = 5\nbest_val_loss = np.inf\npatience_counter = 0\nepochs = 25\nfor epoch in range(epochs):\n    epoch_start_time = time.time()\n    train_loss = 0.0\n    train_correct = 0\n    total_train = 0\n    resnet18.train()\n    for images, labels in train_loader:\n        images, labels = images.to(device), labels.to(device)\n        optimizer.zero_grad()\n        outputs = resnet18(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        train_loss += loss.item()\n        _, predicted = torch.max(outputs.data, 1)\n        total_train += labels.size(0)\n        train_correct += (predicted == labels).sum().item()\n\n    train_accuracy = 100 * train_correct / total_train\n    writer.add_scalar('Loss/Train', train_loss / len(train_loader), epoch)\n    writer.add_scalar('Accuracy/Train', train_accuracy, epoch)\n\n    resnet18.eval()\n    val_loss = 0.0\n    val_correct = 0\n    total_val = 0\n    with torch.no_grad():\n        for images, labels in validation_loader:\n            images, labels = images.to(device), labels.to(device)\n            outputs = resnet18(images)\n            loss = criterion(outputs, labels)\n            val_loss += loss.item()\n            _, predicted = torch.max(outputs.data, 1)\n            total_val += labels.size(0)\n            val_correct += (predicted == labels).sum().item()\n\n    val_accuracy = 100 * val_correct / total_val\n    writer.add_scalar('Loss/Validation', val_loss / len(validation_loader), epoch)\n    writer.add_scalar('Accuracy/Validation', val_accuracy, epoch)\n\n    if val_loss / len(validation_loader) < best_val_loss:\n        print(f\"Validation loss decreased ({best_val_loss:.6f} --> {val_loss / len(validation_loader):.6f}). Saving model ...\")\n        best_val_loss = val_loss / len(validation_loader)\n        torch.save(resnet18.state_dict(), model_save_path)\n        patience_counter = 0\n    else:\n        patience_counter += 1\n        if patience_counter >= patience:\n            print(f\"Early stopping triggered at epoch {epoch+1}\")\n            break\n    scheduler.step()\n    print(f\"Epoch {epoch+1}: Train Loss: {train_loss / len(train_loader):.4f}, \"\n      f\"Train Accuracy: {train_accuracy:.2f}%, \"\n      f\"Val Loss: {val_loss / len(validation_loader):.4f}, \"\n      f\"Val Accuracy: {val_accuracy:.2f}%\")\nwriter.close()","metadata":{"execution":{"iopub.status.busy":"2024-04-19T21:56:18.998649Z","iopub.execute_input":"2024-04-19T21:56:18.999569Z","iopub.status.idle":"2024-04-19T22:07:46.594793Z","shell.execute_reply.started":"2024-04-19T21:56:18.999537Z","shell.execute_reply":"2024-04-19T22:07:46.593797Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Validation loss decreased (inf --> 2.840727). Saving model ...\nEpoch 1: Train Loss: 3.0963, Train Accuracy: 15.11%, Val Loss: 2.8407, Val Accuracy: 18.71%\nEpoch 2: Train Loss: 2.5722, Train Accuracy: 27.41%, Val Loss: 2.8631, Val Accuracy: 23.76%\nValidation loss decreased (2.840727 --> 2.376374). Saving model ...\nEpoch 3: Train Loss: 2.3090, Train Accuracy: 33.67%, Val Loss: 2.3764, Val Accuracy: 34.62%\nValidation loss decreased (2.376374 --> 2.241691). Saving model ...\nEpoch 4: Train Loss: 2.1216, Train Accuracy: 38.42%, Val Loss: 2.2417, Val Accuracy: 39.57%\nEpoch 5: Train Loss: 1.9494, Train Accuracy: 43.47%, Val Loss: 2.3566, Val Accuracy: 34.73%\nValidation loss decreased (2.241691 --> 1.603815). Saving model ...\nEpoch 6: Train Loss: 1.5146, Train Accuracy: 56.19%, Val Loss: 1.6038, Val Accuracy: 55.38%\nValidation loss decreased (1.603815 --> 1.601449). Saving model ...\nEpoch 7: Train Loss: 1.4012, Train Accuracy: 59.67%, Val Loss: 1.6014, Val Accuracy: 54.62%\nValidation loss decreased (1.601449 --> 1.490195). Saving model ...\nEpoch 8: Train Loss: 1.3502, Train Accuracy: 61.15%, Val Loss: 1.4902, Val Accuracy: 55.38%\nEpoch 9: Train Loss: 1.3120, Train Accuracy: 61.82%, Val Loss: 1.5349, Val Accuracy: 55.16%\nEpoch 10: Train Loss: 1.2636, Train Accuracy: 63.21%, Val Loss: 1.5093, Val Accuracy: 56.77%\nValidation loss decreased (1.490195 --> 1.376903). Saving model ...\nEpoch 11: Train Loss: 1.1969, Train Accuracy: 65.37%, Val Loss: 1.3769, Val Accuracy: 60.11%\nEpoch 12: Train Loss: 1.1803, Train Accuracy: 65.99%, Val Loss: 1.5006, Val Accuracy: 58.39%\nEpoch 13: Train Loss: 1.1612, Train Accuracy: 66.14%, Val Loss: 1.4024, Val Accuracy: 59.14%\nEpoch 14: Train Loss: 1.1589, Train Accuracy: 65.88%, Val Loss: 1.3820, Val Accuracy: 58.60%\nEpoch 15: Train Loss: 1.1592, Train Accuracy: 66.49%, Val Loss: 1.4229, Val Accuracy: 58.92%\nEarly stopping triggered at epoch 16\n","output_type":"stream"}]}]}