{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8073566,"sourceType":"datasetVersion","datasetId":4764182}],"dockerImageVersionId":30683,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from torch.utils.data import DataLoader, random_split\nfrom torchvision import datasets, transforms, models\nimport torch\nimport numpy as np\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import classification_report\nfrom torch.utils.tensorboard import SummaryWriter\nfrom sklearn.manifold import TSNE\nfrom torch.optim.lr_scheduler import StepLR\nimport time","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-09T13:04:14.346388Z","iopub.execute_input":"2024-04-09T13:04:14.346713Z","iopub.status.idle":"2024-04-09T13:04:14.352408Z","shell.execute_reply.started":"2024-04-09T13:04:14.346689Z","shell.execute_reply":"2024-04-09T13:04:14.351544Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Transformations\n# We're transforming the images to 224x224, as that's the input size for GoogleNet. We're also normalizing the images.\n\n# Data Augmentation\n# We're using data augmentation to increase the size of the dataset. We're using the following transformations:\n# RandomHorizontalFlip\n# RandomRotation\n# RandomResizedCrop\n# ColorJitter\n# RandomAffine\n\ntransform = transforms.Compose([\n    transforms.Resize(256),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(15),\n    transforms.CenterCrop(224),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n    transforms.ColorJitter()\n])\n\nfull_dataset = datasets.ImageFolder('/kaggle/input/animal-dataset/mammals', transform=transform)\nclass_counts = {class_name: 0 for class_name in full_dataset.classes}\nfor _, index in full_dataset.samples:\n    class_name = full_dataset.classes[index]\n    class_counts[class_name] += 1\nprint(\"Total number of classes:\", len(full_dataset.classes))\nprint(\"Class names:\", full_dataset.classes)\nprint(\"Number of images per class:\")\nfor class_name, count in class_counts.items():\n    print(f\" - {class_name}: {count}\")","metadata":{"execution":{"iopub.status.busy":"2024-04-09T13:04:17.291173Z","iopub.execute_input":"2024-04-09T13:04:17.291552Z","iopub.status.idle":"2024-04-09T13:04:19.189078Z","shell.execute_reply.started":"2024-04-09T13:04:17.291522Z","shell.execute_reply":"2024-04-09T13:04:19.188130Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Total number of classes: 30\nClass names: ['african_elephant', 'alpaca', 'american_bison', 'anteater', 'arctic_fox', 'armadillo', 'baboon', 'badger', 'brown_bear', 'camel', 'giraffe', 'groundhog', 'highland_cattle', 'horse', 'jackal', 'kangaroo', 'koala', 'mongoose', 'mountain_goat', 'opossum', 'orangutan', 'polar_bear', 'porcupine', 'red_panda', 'rhinoceros', 'weasel', 'wildebeest', 'wombat', 'yak', 'zebra']\nNumber of images per class:\n - african_elephant: 347\n - alpaca: 333\n - american_bison: 343\n - anteater: 299\n - arctic_fox: 315\n - armadillo: 331\n - baboon: 330\n - badger: 310\n - brown_bear: 300\n - camel: 254\n - giraffe: 305\n - groundhog: 309\n - highland_cattle: 311\n - horse: 303\n - jackal: 278\n - kangaroo: 317\n - koala: 319\n - mongoose: 287\n - mountain_goat: 328\n - opossum: 330\n - orangutan: 340\n - polar_bear: 356\n - porcupine: 321\n - red_panda: 329\n - rhinoceros: 274\n - weasel: 282\n - wildebeest: 307\n - wombat: 315\n - yak: 254\n - zebra: 272\n","output_type":"stream"}]}]}