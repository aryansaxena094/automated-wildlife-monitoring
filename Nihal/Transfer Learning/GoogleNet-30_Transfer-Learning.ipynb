{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8169528,"sourceType":"datasetVersion","datasetId":4834600}],"dockerImageVersionId":30703,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from torch.utils.data import DataLoader, random_split\nfrom torchvision import datasets, transforms, models\nimport torch\nimport numpy as np\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import classification_report\nfrom torch.utils.tensorboard import SummaryWriter\nfrom sklearn.manifold import TSNE\nfrom torch.optim.lr_scheduler import StepLR\nimport time\nimport torch.nn as nn\nfrom datetime import datetime","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-20T00:00:45.484006Z","iopub.execute_input":"2024-04-20T00:00:45.484371Z","iopub.status.idle":"2024-04-20T00:00:45.490926Z","shell.execute_reply.started":"2024-04-20T00:00:45.484342Z","shell.execute_reply":"2024-04-20T00:00:45.489776Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.Resize(256),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(15),\n    transforms.CenterCrop(224),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n    transforms.ColorJitter()\n])\n\nfull_dataset = datasets.ImageFolder('/kaggle/input/animal-class-30/mammals', transform=transform)\nclass_counts = {class_name: 0 for class_name in full_dataset.classes}\nfor _, index in full_dataset.samples:\n    class_name = full_dataset.classes[index]\n    class_counts[class_name] += 1\nprint(\"Total number of classes:\", len(full_dataset.classes))\nprint(\"Class names:\", full_dataset.classes)\nprint(\"Number of images per class:\")\nfor class_name, count in class_counts.items():\n    print(f\" - {class_name}: {count}\")","metadata":{"execution":{"iopub.status.busy":"2024-04-20T00:01:04.488245Z","iopub.execute_input":"2024-04-20T00:01:04.488627Z","iopub.status.idle":"2024-04-20T00:01:05.793813Z","shell.execute_reply.started":"2024-04-20T00:01:04.488577Z","shell.execute_reply":"2024-04-20T00:01:05.792676Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Total number of classes: 30\nClass names: ['african_elephant', 'alpaca', 'american_bison', 'anteater', 'arctic_fox', 'armadillo', 'baboon', 'badger', 'brown_bear', 'camel', 'giraffe', 'groundhog', 'highland_cattle', 'horse', 'jackal', 'kangaroo', 'koala', 'mongoose', 'mountain_goat', 'opossum', 'orangutan', 'polar_bear', 'porcupine', 'red_panda', 'rhinoceros', 'weasel', 'wildebeest', 'wombat', 'yak', 'zebra']\nNumber of images per class:\n - african_elephant: 347\n - alpaca: 333\n - american_bison: 343\n - anteater: 299\n - arctic_fox: 315\n - armadillo: 331\n - baboon: 330\n - badger: 310\n - brown_bear: 300\n - camel: 254\n - giraffe: 305\n - groundhog: 309\n - highland_cattle: 311\n - horse: 303\n - jackal: 278\n - kangaroo: 317\n - koala: 319\n - mongoose: 287\n - mountain_goat: 328\n - opossum: 330\n - orangutan: 340\n - polar_bear: 356\n - porcupine: 321\n - red_panda: 329\n - rhinoceros: 274\n - weasel: 282\n - wildebeest: 307\n - wombat: 315\n - yak: 254\n - zebra: 272\n","output_type":"stream"}]},{"cell_type":"code","source":"train_size = int(0.8 * len(full_dataset))\ntest_validation_size = len(full_dataset) - train_size\nvalidation_size = test_validation_size // 2\ntest_size = test_validation_size - validation_size\n\ntrain_dataset, test_validation_dataset = random_split(full_dataset, [train_size, test_validation_size])\nvalidation_dataset, test_dataset = random_split(test_validation_dataset, [validation_size, test_size])\n\nprint(\"Size of the entire Dataset: \", len(full_dataset))\nprint(\"Size of the training Dataset: \", len(train_dataset))\nprint(\"Size of the validation Dataset: \", len(validation_dataset))\nprint(\"Size of the test Dataset: \", len(test_dataset))\n\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\nvalidation_loader = DataLoader(validation_dataset, batch_size=32, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-20T00:01:12.307275Z","iopub.execute_input":"2024-04-20T00:01:12.308039Z","iopub.status.idle":"2024-04-20T00:01:12.343260Z","shell.execute_reply.started":"2024-04-20T00:01:12.308003Z","shell.execute_reply":"2024-04-20T00:01:12.342190Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Size of the entire Dataset:  9299\nSize of the training Dataset:  7439\nSize of the validation Dataset:  930\nSize of the test Dataset:  930\n","output_type":"stream"}]}]}