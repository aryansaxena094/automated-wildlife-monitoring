{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8169528,"sourceType":"datasetVersion","datasetId":4834600}],"dockerImageVersionId":30703,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from torch.utils.data import DataLoader, random_split\nfrom torchvision import datasets, transforms, models\nimport torch\nimport numpy as np\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import classification_report\nfrom torch.utils.tensorboard import SummaryWriter\nfrom sklearn.manifold import TSNE\nfrom torch.optim.lr_scheduler import StepLR\nimport time\nimport torch.nn as nn\nfrom datetime import datetime","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-20T00:00:45.484006Z","iopub.execute_input":"2024-04-20T00:00:45.484371Z","iopub.status.idle":"2024-04-20T00:00:45.490926Z","shell.execute_reply.started":"2024-04-20T00:00:45.484342Z","shell.execute_reply":"2024-04-20T00:00:45.489776Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.Resize(256),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(15),\n    transforms.CenterCrop(224),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n    transforms.ColorJitter()\n])\n\nfull_dataset = datasets.ImageFolder('/kaggle/input/animal-class-30/mammals', transform=transform)\nclass_counts = {class_name: 0 for class_name in full_dataset.classes}\nfor _, index in full_dataset.samples:\n    class_name = full_dataset.classes[index]\n    class_counts[class_name] += 1\nprint(\"Total number of classes:\", len(full_dataset.classes))\nprint(\"Class names:\", full_dataset.classes)\nprint(\"Number of images per class:\")\nfor class_name, count in class_counts.items():\n    print(f\" - {class_name}: {count}\")","metadata":{"execution":{"iopub.status.busy":"2024-04-20T00:01:04.488245Z","iopub.execute_input":"2024-04-20T00:01:04.488627Z","iopub.status.idle":"2024-04-20T00:01:05.793813Z","shell.execute_reply.started":"2024-04-20T00:01:04.488577Z","shell.execute_reply":"2024-04-20T00:01:05.792676Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Total number of classes: 30\nClass names: ['african_elephant', 'alpaca', 'american_bison', 'anteater', 'arctic_fox', 'armadillo', 'baboon', 'badger', 'brown_bear', 'camel', 'giraffe', 'groundhog', 'highland_cattle', 'horse', 'jackal', 'kangaroo', 'koala', 'mongoose', 'mountain_goat', 'opossum', 'orangutan', 'polar_bear', 'porcupine', 'red_panda', 'rhinoceros', 'weasel', 'wildebeest', 'wombat', 'yak', 'zebra']\nNumber of images per class:\n - african_elephant: 347\n - alpaca: 333\n - american_bison: 343\n - anteater: 299\n - arctic_fox: 315\n - armadillo: 331\n - baboon: 330\n - badger: 310\n - brown_bear: 300\n - camel: 254\n - giraffe: 305\n - groundhog: 309\n - highland_cattle: 311\n - horse: 303\n - jackal: 278\n - kangaroo: 317\n - koala: 319\n - mongoose: 287\n - mountain_goat: 328\n - opossum: 330\n - orangutan: 340\n - polar_bear: 356\n - porcupine: 321\n - red_panda: 329\n - rhinoceros: 274\n - weasel: 282\n - wildebeest: 307\n - wombat: 315\n - yak: 254\n - zebra: 272\n","output_type":"stream"}]},{"cell_type":"code","source":"train_size = int(0.8 * len(full_dataset))\ntest_validation_size = len(full_dataset) - train_size\nvalidation_size = test_validation_size // 2\ntest_size = test_validation_size - validation_size\n\ntrain_dataset, test_validation_dataset = random_split(full_dataset, [train_size, test_validation_size])\nvalidation_dataset, test_dataset = random_split(test_validation_dataset, [validation_size, test_size])\n\nprint(\"Size of the entire Dataset: \", len(full_dataset))\nprint(\"Size of the training Dataset: \", len(train_dataset))\nprint(\"Size of the validation Dataset: \", len(validation_dataset))\nprint(\"Size of the test Dataset: \", len(test_dataset))\n\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\nvalidation_loader = DataLoader(validation_dataset, batch_size=32, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-20T00:01:12.307275Z","iopub.execute_input":"2024-04-20T00:01:12.308039Z","iopub.status.idle":"2024-04-20T00:01:12.343260Z","shell.execute_reply.started":"2024-04-20T00:01:12.308003Z","shell.execute_reply":"2024-04-20T00:01:12.342190Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Size of the entire Dataset:  9299\nSize of the training Dataset:  7439\nSize of the validation Dataset:  930\nSize of the test Dataset:  930\n","output_type":"stream"}]},{"cell_type":"code","source":"googlenet = models.googlenet(pretrained=True)  # Enable transfer learning\nnum_classes = 30\ngooglenet.fc = nn.Linear(googlenet.fc.in_features, num_classes)  # Adapt the final layer\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ngooglenet.to(device)\ncriterion = nn.CrossEntropyLoss()\nlearning_rate = 0.002\noptimizer = torch.optim.SGD(googlenet.parameters(), lr=learning_rate, momentum=0.9)\nscheduler = StepLR(optimizer, step_size=5, gamma=0.1)\n\nsimple_name = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\nwriter = SummaryWriter(f'runs/{simple_name}')\nmodel_save_path = 'googlenet_best_model.pth'","metadata":{"execution":{"iopub.status.busy":"2024-04-20T00:01:53.284083Z","iopub.execute_input":"2024-04-20T00:01:53.285101Z","iopub.status.idle":"2024-04-20T00:01:53.541728Z","shell.execute_reply.started":"2024-04-20T00:01:53.285062Z","shell.execute_reply":"2024-04-20T00:01:53.540760Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"patience = 5\nbest_val_loss = np.inf\npatience_counter = 0\nepochs = 25\nfor epoch in range(epochs):\n    epoch_start_time = time.time()\n    train_loss = 0.0\n    train_correct = 0\n    total_train = 0\n    googlenet.train()\n    for images, labels in train_loader:\n        images, labels = images.to(device), labels.to(device)\n        optimizer.zero_grad()\n        outputs = googlenet(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        train_loss += loss.item()\n        _, predicted = torch.max(outputs.data, 1)\n        total_train += labels.size(0)\n        train_correct += (predicted == labels).sum().item()\n\n    train_accuracy = 100 * train_correct / total_train\n    writer.add_scalar('Loss/Train', train_loss / len(train_loader), epoch)\n    writer.add_scalar('Accuracy/Train', train_accuracy, epoch)\n\n    googlenet.eval()\n    val_loss = 0.0\n    val_correct = 0\n    total_val = 0\n    with torch.no_grad():\n        for images, labels in validation_loader:\n            images, labels = images.to(device), labels.to(device)\n            outputs = googlenet(images)\n            loss = criterion(outputs, labels)\n            val_loss += loss.item()\n            _, predicted = torch.max(outputs.data, 1)\n            total_val += labels.size(0)\n            val_correct += (predicted == labels).sum().item()\n\n    val_accuracy = 100 * val_correct / total_val\n    writer.add_scalar('Loss/Validation', val_loss / len(validation_loader), epoch)\n    writer.add_scalar('Accuracy/Validation', val_accuracy, epoch)\n\n    if val_loss / len(validation_loader) < best_val_loss:\n        print(f\"Validation loss decreased ({best_val_loss:.6f} --> {val_loss / len(validation_loader):.6f}). Saving model ...\")\n        best_val_loss = val_loss / len(validation_loader)\n        torch.save(googlenet.state_dict(), model_save_path)\n        patience_counter = 0\n    else:\n        patience_counter += 1\n        if patience_counter >= patience:\n            print(f\"Early stopping triggered at epoch {epoch+1}\")\n            break\n    scheduler.step()\n    print(f\"Epoch {epoch+1}: Train Loss: {train_loss / len(train_loader):.4f}, \"\n      f\"Train Accuracy: {train_accuracy:.2f}%, \"\n      f\"Val Loss: {val_loss / len(validation_loader):.4f}, \"\n      f\"Val Accuracy: {val_accuracy:.2f}%\")\nwriter.close()","metadata":{"execution":{"iopub.status.busy":"2024-04-20T00:02:17.173530Z","iopub.execute_input":"2024-04-20T00:02:17.174299Z","iopub.status.idle":"2024-04-20T00:18:00.903045Z","shell.execute_reply.started":"2024-04-20T00:02:17.174267Z","shell.execute_reply":"2024-04-20T00:18:00.901962Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Validation loss decreased (inf --> 0.548581). Saving model ...\nEpoch 1: Train Loss: 1.6641, Train Accuracy: 69.43%, Val Loss: 0.5486, Val Accuracy: 90.75%\nValidation loss decreased (0.548581 --> 0.267211). Saving model ...\nEpoch 2: Train Loss: 0.4469, Train Accuracy: 91.54%, Val Loss: 0.2672, Val Accuracy: 93.98%\nValidation loss decreased (0.267211 --> 0.214153). Saving model ...\nEpoch 3: Train Loss: 0.2713, Train Accuracy: 94.48%, Val Loss: 0.2142, Val Accuracy: 94.73%\nValidation loss decreased (0.214153 --> 0.185341). Saving model ...\nEpoch 4: Train Loss: 0.1982, Train Accuracy: 95.79%, Val Loss: 0.1853, Val Accuracy: 94.95%\nValidation loss decreased (0.185341 --> 0.158330). Saving model ...\nEpoch 5: Train Loss: 0.1516, Train Accuracy: 96.61%, Val Loss: 0.1583, Val Accuracy: 95.59%\nValidation loss decreased (0.158330 --> 0.154460). Saving model ...\nEpoch 6: Train Loss: 0.1175, Train Accuracy: 97.67%, Val Loss: 0.1545, Val Accuracy: 95.59%\nEpoch 7: Train Loss: 0.1084, Train Accuracy: 98.00%, Val Loss: 0.1571, Val Accuracy: 95.70%\nValidation loss decreased (0.154460 --> 0.152788). Saving model ...\nEpoch 8: Train Loss: 0.1069, Train Accuracy: 98.12%, Val Loss: 0.1528, Val Accuracy: 95.48%\nEpoch 9: Train Loss: 0.1045, Train Accuracy: 98.14%, Val Loss: 0.1867, Val Accuracy: 96.13%\nEpoch 10: Train Loss: 0.1085, Train Accuracy: 97.89%, Val Loss: 0.1550, Val Accuracy: 95.81%\nEpoch 11: Train Loss: 0.1058, Train Accuracy: 97.88%, Val Loss: 0.1567, Val Accuracy: 95.16%\nValidation loss decreased (0.152788 --> 0.149494). Saving model ...\nEpoch 12: Train Loss: 0.1003, Train Accuracy: 98.24%, Val Loss: 0.1495, Val Accuracy: 95.16%\nValidation loss decreased (0.149494 --> 0.143265). Saving model ...\nEpoch 13: Train Loss: 0.0969, Train Accuracy: 98.37%, Val Loss: 0.1433, Val Accuracy: 96.13%\nEpoch 14: Train Loss: 0.1051, Train Accuracy: 98.01%, Val Loss: 0.1763, Val Accuracy: 96.24%\nEpoch 15: Train Loss: 0.0982, Train Accuracy: 98.37%, Val Loss: 0.1461, Val Accuracy: 96.02%\nEpoch 16: Train Loss: 0.0985, Train Accuracy: 98.44%, Val Loss: 0.1483, Val Accuracy: 95.91%\nEpoch 17: Train Loss: 0.0998, Train Accuracy: 98.16%, Val Loss: 0.1553, Val Accuracy: 96.02%\nEarly stopping triggered at epoch 18\n","output_type":"stream"}]}]}