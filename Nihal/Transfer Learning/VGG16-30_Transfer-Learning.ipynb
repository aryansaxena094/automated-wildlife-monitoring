{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8169616,"sourceType":"datasetVersion","datasetId":4834647}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from torch.utils.data import DataLoader, random_split\nfrom torchvision import datasets, transforms, models\nimport torch\nimport numpy as np\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import classification_report\nfrom torch.utils.tensorboard import SummaryWriter\nfrom sklearn.manifold import TSNE\nfrom torch.optim.lr_scheduler import StepLR\nimport time\nimport torch.nn as nn\nfrom datetime import datetime","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-20T00:32:15.396137Z","iopub.execute_input":"2024-04-20T00:32:15.396868Z","iopub.status.idle":"2024-04-20T00:32:15.404247Z","shell.execute_reply.started":"2024-04-20T00:32:15.396832Z","shell.execute_reply":"2024-04-20T00:32:15.403208Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.Resize(256),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(15),\n    transforms.CenterCrop(224),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n    transforms.ColorJitter()\n])\n\nfull_dataset = datasets.ImageFolder('/kaggle/input/class-30/mammals', transform=transform)\nclass_counts = {class_name: 0 for class_name in full_dataset.classes}\nfor _, index in full_dataset.samples:\n    class_name = full_dataset.classes[index]\n    class_counts[class_name] += 1\nprint(\"Total number of classes:\", len(full_dataset.classes))\nprint(\"Class names:\", full_dataset.classes)\nprint(\"Number of images per class:\")\nfor class_name, count in class_counts.items():\n    print(f\" - {class_name}: {count}\")","metadata":{"execution":{"iopub.status.busy":"2024-04-20T00:32:34.033604Z","iopub.execute_input":"2024-04-20T00:32:34.034022Z","iopub.status.idle":"2024-04-20T00:32:35.578695Z","shell.execute_reply.started":"2024-04-20T00:32:34.033986Z","shell.execute_reply":"2024-04-20T00:32:35.577405Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Total number of classes: 30\nClass names: ['african_elephant', 'alpaca', 'american_bison', 'anteater', 'arctic_fox', 'armadillo', 'baboon', 'badger', 'brown_bear', 'camel', 'giraffe', 'groundhog', 'highland_cattle', 'horse', 'jackal', 'kangaroo', 'koala', 'mongoose', 'mountain_goat', 'opossum', 'orangutan', 'polar_bear', 'porcupine', 'red_panda', 'rhinoceros', 'weasel', 'wildebeest', 'wombat', 'yak', 'zebra']\nNumber of images per class:\n - african_elephant: 347\n - alpaca: 333\n - american_bison: 343\n - anteater: 299\n - arctic_fox: 315\n - armadillo: 331\n - baboon: 330\n - badger: 310\n - brown_bear: 300\n - camel: 254\n - giraffe: 305\n - groundhog: 309\n - highland_cattle: 311\n - horse: 303\n - jackal: 278\n - kangaroo: 317\n - koala: 319\n - mongoose: 287\n - mountain_goat: 328\n - opossum: 330\n - orangutan: 340\n - polar_bear: 356\n - porcupine: 321\n - red_panda: 329\n - rhinoceros: 274\n - weasel: 282\n - wildebeest: 307\n - wombat: 315\n - yak: 254\n - zebra: 272\n","output_type":"stream"}]},{"cell_type":"code","source":"\ntrain_size = int(0.8 * len(full_dataset))\ntest_validation_size = len(full_dataset) - train_size\nvalidation_size = test_validation_size // 2\ntest_size = test_validation_size - validation_size\n\ntrain_dataset, test_validation_dataset = random_split(full_dataset, [train_size, test_validation_size])\nvalidation_dataset, test_dataset = random_split(test_validation_dataset, [validation_size, test_size])\n\nprint(\"Size of the entire Dataset: \", len(full_dataset))\nprint(\"Size of the training Dataset: \", len(train_dataset))\nprint(\"Size of the validation Dataset: \", len(validation_dataset))\nprint(\"Size of the test Dataset: \", len(test_dataset))\n\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\nvalidation_loader = DataLoader(validation_dataset, batch_size=32, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-20T00:32:42.321359Z","iopub.execute_input":"2024-04-20T00:32:42.321794Z","iopub.status.idle":"2024-04-20T00:32:42.350292Z","shell.execute_reply.started":"2024-04-20T00:32:42.321757Z","shell.execute_reply":"2024-04-20T00:32:42.349145Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Size of the entire Dataset:  9299\nSize of the training Dataset:  7439\nSize of the validation Dataset:  930\nSize of the test Dataset:  930\n","output_type":"stream"}]},{"cell_type":"code","source":"vgg16 = models.vgg16(pretrained=True)\nvgg16.classifier[6] = nn.Linear(\n    vgg16.classifier[6].in_features, 30\n    )\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nvgg16.to(device)\ncriterion = torch.nn.CrossEntropyLoss()\nlearning_rate = 0.001\noptimizer = torch.optim.SGD(vgg16.parameters(), lr=learning_rate, momentum=0.9)\nstep_size = 2\nscheduler = StepLR(optimizer, step_size, gamma=0.1)\nsimple_name = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\nwriter = SummaryWriter(f'runs/{simple_name}')\nmodel_save_path = 'vgg16_best_model.pth'","metadata":{"execution":{"iopub.status.busy":"2024-04-20T00:33:05.646804Z","iopub.execute_input":"2024-04-20T00:33:05.647816Z","iopub.status.idle":"2024-04-20T00:33:07.759309Z","shell.execute_reply.started":"2024-04-20T00:33:05.647778Z","shell.execute_reply":"2024-04-20T00:33:07.758381Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"patience = 5\nbest_val_loss = np.inf\npatience_counter = 0\nepochs = 25\nfor epoch in range(epochs):\n    epoch_start_time = time.time()\n    train_loss = 0.0\n    train_correct = 0\n    total_train = 0\n    vgg16.train()\n    for images, labels in train_loader:\n        images, labels = images.to(device), labels.to(device)\n        optimizer.zero_grad()\n        outputs = vgg16(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        train_loss += loss.item()\n        _, predicted = torch.max(outputs.data, 1)\n        total_train += labels.size(0)\n        train_correct += (predicted == labels).sum().item()\n\n    train_accuracy = 100 * train_correct / total_train\n    writer.add_scalar('Loss/Train', train_loss / len(train_loader), epoch)\n    writer.add_scalar('Accuracy/Train', train_accuracy, epoch)\n\n    vgg16.eval()\n    val_loss = 0.0\n    val_correct = 0\n    total_val = 0\n    with torch.no_grad():\n        for images, labels in validation_loader:\n            images, labels = images.to(device), labels.to(device)\n            outputs = vgg16(images)\n            loss = criterion(outputs, labels)\n            val_loss += loss.item()\n            _, predicted = torch.max(outputs.data, 1)\n            total_val += labels.size(0)\n            val_correct += (predicted == labels).sum().item()\n\n    val_accuracy = 100 * val_correct / total_val\n    writer.add_scalar('Loss/Validation', val_loss / len(validation_loader), epoch)\n    writer.add_scalar('Accuracy/Validation', val_accuracy, epoch)\n\n    if val_loss / len(validation_loader) < best_val_loss:\n        print(f\"Validation loss decreased ({best_val_loss:.6f} --> {val_loss / len(validation_loader):.6f}). Saving model ...\")\n        best_val_loss = val_loss / len(validation_loader)\n        torch.save(vgg16.state_dict(), model_save_path)\n        patience_counter = 0\n    else:\n        patience_counter += 1\n        if patience_counter >= patience:\n            print(f\"Early stopping triggered at epoch {epoch+1}\")\n            break\n    scheduler.step()\n    print(f\"Epoch {epoch+1}: Train Loss: {train_loss / len(train_loader):.4f}, \"\n      f\"Train Accuracy: {train_accuracy:.2f}%, \"\n      f\"Val Loss: {val_loss / len(validation_loader):.4f}, \"\n      f\"Val Accuracy: {val_accuracy:.2f}%\")\nwriter.close()","metadata":{"execution":{"iopub.status.busy":"2024-04-20T00:33:22.208333Z","iopub.execute_input":"2024-04-20T00:33:22.209071Z","iopub.status.idle":"2024-04-20T01:00:38.651843Z","shell.execute_reply.started":"2024-04-20T00:33:22.209020Z","shell.execute_reply":"2024-04-20T01:00:38.650367Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Validation loss decreased (inf --> 0.337667). Saving model ...\nEpoch 1: Train Loss: 0.7567, Train Accuracy: 78.83%, Val Loss: 0.3377, Val Accuracy: 90.11%\nValidation loss decreased (0.337667 --> 0.233262). Saving model ...\nEpoch 2: Train Loss: 0.2917, Train Accuracy: 91.06%, Val Loss: 0.2333, Val Accuracy: 92.04%\nValidation loss decreased (0.233262 --> 0.157249). Saving model ...\nEpoch 3: Train Loss: 0.1370, Train Accuracy: 95.87%, Val Loss: 0.1572, Val Accuracy: 95.48%\nValidation loss decreased (0.157249 --> 0.151554). Saving model ...\nEpoch 4: Train Loss: 0.1155, Train Accuracy: 96.14%, Val Loss: 0.1516, Val Accuracy: 95.27%\nValidation loss decreased (0.151554 --> 0.150623). Saving model ...\nEpoch 5: Train Loss: 0.0959, Train Accuracy: 97.03%, Val Loss: 0.1506, Val Accuracy: 95.59%\nEpoch 6: Train Loss: 0.0934, Train Accuracy: 97.06%, Val Loss: 0.1596, Val Accuracy: 95.48%\nValidation loss decreased (0.150623 --> 0.149654). Saving model ...\nEpoch 7: Train Loss: 0.1001, Train Accuracy: 96.80%, Val Loss: 0.1497, Val Accuracy: 95.48%\nEpoch 8: Train Loss: 0.0949, Train Accuracy: 97.00%, Val Loss: 0.1578, Val Accuracy: 95.38%\nEpoch 9: Train Loss: 0.0926, Train Accuracy: 97.10%, Val Loss: 0.1592, Val Accuracy: 94.62%\nEpoch 10: Train Loss: 0.0985, Train Accuracy: 97.16%, Val Loss: 0.1505, Val Accuracy: 95.16%\nEpoch 11: Train Loss: 0.0978, Train Accuracy: 96.96%, Val Loss: 0.1592, Val Accuracy: 95.48%\nEarly stopping triggered at epoch 12\n","output_type":"stream"}]}]}